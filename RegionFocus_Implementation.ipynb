{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjVqlL7m2m7e"
      },
      "source": [
        "##RegionFocus: A Python Implementation of a Visual Grounding Framework\n",
        "\n",
        "This notebook is an implementation of the research paper \"Visual Test-time Scaling for GUI Agent Grounding\" ([arXiv:2505.00684](https://arxiv.org/pdf/2505.00684)). The goal is to replicate the paper's core logic (test-time scaling, dynamically zooming, and an 'image-as-map' landmark system), and test its effectiveness on a general-purpose Vision-Language Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUTt1ZVTP_Fe"
      },
      "outputs": [],
      "source": [
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt-get install -y ./google-chrome-stable_current_amd64.deb chromium-chromedriver\n",
        "\n",
        "!pip install selenium transformers torch pillow accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2P64odQvRO4_"
      },
      "outputs": [],
      "source": [
        "#demo webpage\n",
        "\n",
        "html_content = \"\"\"\n",
        "<style>\n",
        "  body { padding: 40px; font-family: sans-serif; }\n",
        "  .btn {\n",
        "    padding: 20px;\n",
        "    font-size: 24px;\n",
        "    border-radius: 8px;\n",
        "    margin: 20px;\n",
        "    cursor: pointer;\n",
        "  }\n",
        "  /* This is the FAKE button */\n",
        "  #cancel-btn { background-color: #f77; border: 2px solid #a00; }\n",
        "\n",
        "  /* This is the REAL button */\n",
        "  #submit-btn { background-color: #7f7; border: 2px solid #0a0; }\n",
        "</style>\n",
        "\n",
        "<body>\n",
        "  <h1>Submit Your Report</h1>\n",
        "  <p>Please confirm your submission. One button is fake.</p>\n",
        "\n",
        "  <button id=\"cancel-btn\" class=\"btn\" onclick=\"alert('Fake Button Clicked!')\">Submit</button>\n",
        "\n",
        "  <button id=\"submit-btn\" class=\"btn\" onclick=\"alert('Real Button Clicked!')\">Submit</button>\n",
        "\n",
        "</body>\n",
        "\"\"\"\n",
        "\n",
        "with open(\"index.html\", \"w\") as f:\n",
        "    f.write(html_content)\n",
        "\n",
        "print(\"Challenge file 'index.html' created.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDdvg-K8RfQe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import LlavaNextProcessor, LlavaNextForConditionalGeneration, BitsAndBytesConfig\n",
        "import re\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "\n",
        "# --- 1. Define 4-bit Quantization Config ---\n",
        "print(\"Setting up 4-bit quantization config...\")\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "# --- 2. Load Model and Processor ---\n",
        "print(\"Loading LLaVA model in 4-bit... (This may take a few minutes)\")\n",
        "model_id = \"llava-hf/llava-v1.6-vicuna-7b-hf\"\n",
        "\n",
        "processor = LlavaNextProcessor.from_pretrained(model_id)\n",
        "\n",
        "model = LlavaNextForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quantization_config,\n",
        "    low_cpu_mem_usage=True\n",
        ")\n",
        "print(\"LLaVA model loaded successfully in 4-bit.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w6kjyk4KMlGJ"
      },
      "outputs": [],
      "source": [
        "# --- 3. VLM Inference Helper Function ---\n",
        "def get_vlm_coordinates(image, prompt_text, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Feeds an image and a text prompt to LLaVA and parses\n",
        "    its response to find [x, y] coordinates.\n",
        "\n",
        "    HANDLES BOTH [x, y] AND [x1, y1, x2, y2] FORMATS.\n",
        "    \"\"\"\n",
        "    prompt = f\"[USER]: <image>\\n{prompt_text} Please respond *only* with the coordinates of the center of this element in the format [x, y].\\n[ASSISTANT]:\"\n",
        "\n",
        "    inputs = processor(text=prompt, images=image, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "    output = model.generate(**inputs, max_new_tokens=100)\n",
        "    response_text = processor.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "    # Regex for 4 numbers (bbox): [x1, y1, x2, y2]\n",
        "    bbox_match = re.search(r'\\[(\\d+\\.?\\d*),\\s*(\\d+\\.?\\d*),\\s*(\\d+\\.?\\d*),\\s*(\\d+\\.?\\d*)\\]', response_text)\n",
        "    # Regex for 2 numbers (center): [x, y]\n",
        "    center_match = re.search(r'\\[(\\d+\\.?\\d*),\\s*(\\d+\\.?\\d*)\\]', response_text)\n",
        "\n",
        "    if bbox_match:\n",
        "        # --- HANDLE BOUNDING BOX ---\n",
        "        x1 = float(bbox_match.group(1))\n",
        "        y1 = float(bbox_match.group(2))\n",
        "        x2 = float(bbox_match.group(3))\n",
        "        y2 = float(bbox_match.group(4))\n",
        "\n",
        "        print(f\"VLM responded with BBOX: [{x1}, {y1}, {x2}, {y2}]\")\n",
        "\n",
        "        # Check if relative (0-1) and convert\n",
        "        if 0.0 <= x1 <= 1.0 and 0.0 <= y1 <= 1.0:\n",
        "            x1_abs = x1 * img_width\n",
        "            y1_abs = y1 * img_height\n",
        "            x2_abs = x2 * img_width\n",
        "            y2_abs = y2 * img_height\n",
        "        else:\n",
        "            x1_abs, y1_abs, x2_abs, y2_abs = x1, y1, x2, y2\n",
        "\n",
        "        # Calculate center point from bbox\n",
        "        center_x = int((x1_abs + x2_abs) / 2)\n",
        "        center_y = int((y1_abs + y2_abs) / 2)\n",
        "\n",
        "        print(f\"Calculated center from bbox: [{center_x}, {center_y}]\")\n",
        "        return (center_x, center_y)\n",
        "\n",
        "    elif center_match:\n",
        "        # --- HANDLE CENTER POINT (Original Logic) ---\n",
        "        x_val = float(center_match.group(1))\n",
        "        y_val = float(center_match.group(2))\n",
        "\n",
        "        print(f\"VLM responded with CENTER: [{x_val}, {y_val}]\")\n",
        "\n",
        "        if 0.0 <= x_val <= 1.0 and 0.0 <= y_val <= 1.0:\n",
        "            x_abs = int(x_val * img_width)\n",
        "            y_abs = int(y_val * img_height)\n",
        "            print(f\"Converted relative coords to absolute: [{x_abs}, {y_abs}]\")\n",
        "            return (x_abs, y_abs)\n",
        "        else:\n",
        "            print(\"VLM gave absolute coords.\")\n",
        "            return (int(x_val), int(y_val))\n",
        "\n",
        "    else:\n",
        "        # --- HANDLE FAILURE ---\n",
        "        print(f\"VLM response was unparsable: {response_text.split('ASSISTANT:')[-1].strip()}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaOoUj_3RmP3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import display\n",
        "\n",
        "# --- 1. Image-as-Map Drawing Function ---\n",
        "try:\n",
        "    font_path = \"/usr/share/fonts/truetype/liberation/LiberationMono-Regular.ttf\" # Example font path\n",
        "    font_size = 30\n",
        "    font = ImageFont.truetype(font_path, font_size)\n",
        "    print(f\"Loaded font: {font_path} with size {font_size}\")\n",
        "except IOError:\n",
        "    print(\"Font not found. Using default font (no size/thickness control).\")\n",
        "    try:\n",
        "        font = ImageFont.load_default()\n",
        "    except IOError:\n",
        "        font = None\n",
        "marker_char = \"o\"\n",
        "\n",
        "def add_landmarks_to_image(base_image, coordinates_list, save_path):\n",
        "    \"\"\"\n",
        "    Draws pink markers on a *copy* of an image and saves it.\n",
        "    Increased size and simulated thickness by drawing multiple times.\n",
        "    \"\"\"\n",
        "    image = base_image.copy().convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    offsets = [(-1, -1), (-1, 1), (1, -1), (1, 1), (0, 0)] # Draw center and corners\n",
        "    for (x, y) in coordinates_list:\n",
        "        for ox, oy in offsets:\n",
        "            draw.text((x - 15 + ox, y - 25 + oy), marker_char, fill=\"purple\", font=font)\n",
        "\n",
        "    image.save(save_path)\n",
        "    print(f\"Saved map with {len(coordinates_list)} landmark(s) to {save_path}\")\n",
        "    return Image.open(save_path)\n",
        "\n",
        "# --- 2. Bounding Box Proposal Function ---\n",
        "def get_fixed_bboxes(focal_point, img_width, img_height):\n",
        "    \"\"\"\n",
        "    Calculates 4 fixed-ratio bounding boxes centered\n",
        "    on the focal_point, as described in the paper.\n",
        "    \"\"\"\n",
        "    (cx, cy) = focal_point\n",
        "\n",
        "    ratios = [\n",
        "        (0.5, 0.5),\n",
        "        (0.3, 0.3),\n",
        "        (0.4, 0.8),\n",
        "        (0.8, 0.4)\n",
        "    ]\n",
        "\n",
        "    bboxes = []\n",
        "    for (w_ratio, h_ratio) in ratios:\n",
        "        width = w_ratio * img_width\n",
        "        height = h_ratio * img_height\n",
        "\n",
        "        x1 = max(0, cx - width / 2)\n",
        "        y1 = max(0, cy - height / 2)\n",
        "        x2 = min(img_width, cx + width / 2)\n",
        "        y2 = min(img_height, cy + height / 2)\n",
        "\n",
        "        bboxes.append((int(x1), int(y1), int(x2), int(y2)))\n",
        "\n",
        "    print(f\"Generated 4 fixed-ratio bounding boxes around {focal_point}\")\n",
        "    return bboxes\n",
        "\n",
        "# --- Draw Bounding Boxes ---\n",
        "def draw_bboxes_on_image(base_image, bboxes, save_path):\n",
        "    \"\"\"\n",
        "    Draws the 4 proposed bounding boxes on an image.\n",
        "    \"\"\"\n",
        "    image = base_image.copy().convert(\"RGB\")\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    colors = [\"red\", \"green\", \"blue\", \"yellow\"]\n",
        "\n",
        "    for i, box in enumerate(bboxes):\n",
        "        draw.rectangle(box, outline=colors[i % len(colors)], width=3)\n",
        "\n",
        "    image.save(save_path)\n",
        "    print(f\"Saved bbox visualization to {save_path}\")\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sap42RYxRoCb"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.action_chains import ActionChains\n",
        "from selenium.webdriver.common.by import By\n",
        "import time\n",
        "\n",
        "# --- 1. Setup Selenium Driver ---\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome(options=options)\n",
        "\n",
        "driver.set_window_size(1024, 768)\n",
        "\n",
        "html_file_path = \"file://\" + os.path.abspath(\"index.html\")\n",
        "driver.get(html_file_path)\n",
        "time.sleep(1)\n",
        "\n",
        "print(\"Browser loaded.\")\n",
        "\n",
        "# --- 2. Helper to Check Clicks ---\n",
        "def check_click_success(coords):\n",
        "    if not coords:\n",
        "        return None\n",
        "    try:\n",
        "        element = driver.execute_script(\n",
        "            \"return document.elementFromPoint(arguments[0], arguments[1]);\",\n",
        "            coords[0], coords[1]\n",
        "        )\n",
        "        if element:\n",
        "            return element.get_attribute(\"id\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error checking click: {e}\")\n",
        "        return None\n",
        "\n",
        "# =======================================================\n",
        "# STEP A: INITIAL PREDICTION\n",
        "# =======================================================\n",
        "print(\"\\n--- STEP A: Initial Prediction ---\")\n",
        "driver.save_screenshot(\"screenshot_1.png\")\n",
        "img_1 = Image.open(\"screenshot_1.png\")\n",
        "img_width, img_height = img_1.size\n",
        "\n",
        "initial_prompt = \"Find the 'Submit' button. It's next to another 'Submit' button.\"\n",
        "coords_1 = get_vlm_coordinates(img_1, initial_prompt, img_width, img_height)\n",
        "\n",
        "# --- VISUAL 1: Show the first (wrong) click ---\n",
        "if coords_1:\n",
        "    print(\"\\nVISUAL: Initial VLM Prediction\")\n",
        "    display(add_landmarks_to_image(img_1, [coords_1], \"initial_prediction_map.png\"))\n",
        "else:\n",
        "    print(\"No initial coordinates found.\")\n",
        "\n",
        "# =======================================================\n",
        "# STEP B: TRIGGER CONDITION\n",
        "# =======================================================\n",
        "print(\"\\n--- STEP B: Trigger Condition Check ---\")\n",
        "clicked_element_id = check_click_success(coords_1)\n",
        "print(f\"Initial click at {coords_1} would hit element: '{clicked_element_id}'\")\n",
        "\n",
        "if clicked_element_id == \"submit-btn\":\n",
        "    print(\"ðŸŽ‰ SUCCESS on the first try! (This is unlikely)\")\n",
        "\n",
        "elif clicked_element_id is None:\n",
        "    print(\"FAILURE: VLM did not provide clickable coordinates.\")\n",
        "\n",
        "else:\n",
        "    print(f\"FAILURE: VLM clicked the wrong button ('{clicked_element_id}').\")\n",
        "    print(\"ðŸ”¥ REGIONFOCUS ACTIVATED ðŸ”¥\")\n",
        "\n",
        "    # =======================================================\n",
        "    # STEP C: REGIONFOCUS PROCESS\n",
        "    # =======================================================\n",
        "\n",
        "    # --- C.1: Image-as-Map (History) ---\n",
        "    print(\"\\n--- C.1: Marking history on map... ---\")\n",
        "    history_map = add_landmarks_to_image(img_1, [coords_1], \"history_map.png\")\n",
        "\n",
        "    # --- VISUAL 2: Show the history map ---\n",
        "    print(\"\\nVISUAL: History Map (Input for C.2)\")\n",
        "    display(history_map)\n",
        "\n",
        "    # --- C.2: Focal Point Proposal ---\n",
        "    print(\"\\n--- C.2: Proposing new focal point... ---\")\n",
        "    focal_point_prompt = f\"I tried clicking the 'Submit' button at the pink marker ({marker_char}) and it was wrong. Find the *other* 'Submit' button and give its [x, y] coordinates as a new focal point.\"\n",
        "    focal_point = get_vlm_coordinates(history_map, focal_point_prompt, img_width, img_height)\n",
        "\n",
        "    if focal_point:\n",
        "        # --- C.3: Bounding Box Proposal ---\n",
        "        print(\"\\n--- C.3: Proposing fixed-ratio bboxes... ---\")\n",
        "        bboxes = get_fixed_bboxes(focal_point, img_width, img_height)\n",
        "\n",
        "        # --- VISUAL 3: Show the proposed regions ---\n",
        "        print(\"\\nVISUAL: Proposed Bounding Boxes (Input for C.4)\")\n",
        "        bbox_map = draw_bboxes_on_image(img_1, bboxes, \"bbox_map.png\")\n",
        "        display(bbox_map)\n",
        "\n",
        "        # --- C.4: Candidate Prediction (The \"Zoom\") ---\n",
        "        print(\"\\n--- C.4: Predicting action for each region... ---\")\n",
        "        colors = [\"red\", \"green\", \"blue\", \"yellow\"]\n",
        "        candidates = []\n",
        "        for i, box in enumerate(bboxes):\n",
        "            region_crop = img_1.crop(box)\n",
        "            region_crop.save(f\"region_{i}.png\")\n",
        "\n",
        "            crop_width, crop_height = region_crop.size\n",
        "\n",
        "            print(f\"  Analyzing region {i} ({crop_width}x{crop_height})...\")\n",
        "\n",
        "\n",
        "\n",
        "            region_prompt = \"Find the 'Submit' button in this small image. Give its *local* coordinates [x, y].\"\n",
        "            local_coords = get_vlm_coordinates(region_crop, region_prompt, crop_width, crop_height)\n",
        "\n",
        "            # --- VISUAL 4: Show the crop being analyzed ---\n",
        "            print(f\"  VISUAL: Region {i} Crop\")\n",
        "            draw = ImageDraw.Draw(region_crop)\n",
        "            draw.rectangle((0, 0, crop_width - 1, crop_height - 1), outline=colors[i % len(colors)], width=5)\n",
        "            display(add_landmarks_to_image(region_crop, [local_coords], f\"Region_{i}_Crop.png\"))\n",
        "\n",
        "            if local_coords:\n",
        "                global_x = box[0] + local_coords[0]\n",
        "                global_y = box[1] + local_coords[1]\n",
        "                candidates.append((global_x, global_y))\n",
        "                print(f\"  Found candidate at {global_x, global_y}\")\n",
        "\n",
        "        # --- C.5: Action Aggregation ---\n",
        "        print(\"\\n--- C.5: Aggregating final action... ---\")\n",
        "        if candidates:\n",
        "            aggregation_map = add_landmarks_to_image(img_1, candidates, \"aggregation_map.png\")\n",
        "\n",
        "            # --- VISUAL 5: Show the aggregation map ---\n",
        "            print(\"\\nVISUAL: Aggregation Map (Input for C.5)\")\n",
        "            display(aggregation_map)\n",
        "\n",
        "            agg_prompt = f\"Here are {len(candidates)} candidates for the *correct* 'Submit' button, marked with {marker_char}. Which one is the right one to click? Respond with its [x, y] coordinates.\"\n",
        "            final_coords = get_vlm_coordinates(aggregation_map, agg_prompt, img_width, img_height)\n",
        "\n",
        "            # =======================================================\n",
        "            # STEP D: EXECUTE FINAL ACTION\n",
        "            # =======================================================\n",
        "            print(\"\\n--- STEP D: Executing Final Action ---\")\n",
        "            final_clicked_id = check_click_success(final_coords)\n",
        "            print(f\"Final click at {final_coords} would hit element: '{final_clicked_id}'\")\n",
        "\n",
        "            # --- VISUAL 6: Show the final action ---\n",
        "            print(\"\\nVISUAL: Final Chosen Action\")\n",
        "            display(add_landmarks_to_image(img_1, [final_coords], \"final_action_map.png\"))\n",
        "\n",
        "            if final_clicked_id == \"submit-btn\":\n",
        "                print(\"ðŸŽ‰ðŸŽ‰ðŸŽ‰ REGIONFOCUS SUCCESS! ðŸŽ‰ðŸŽ‰ðŸŽ‰\")\n",
        "            else:\n",
        "                print(\"ðŸ˜¥ REGIONFOCUS FAILED. Final click was also wrong.\")\n",
        "        else:\n",
        "            print(\"ðŸ˜¥ REGIONFOCUS FAILED. No candidates found in any region.\")\n",
        "    else:\n",
        "        print(\"ðŸ˜¥ REGIONFOCUS FAILED. VLM could not propose a new focal point.\")\n",
        "\n",
        "# --- 6. Cleanup ---\n",
        "print(\"\\n--- Cleanup ---\")\n",
        "driver.quit()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}